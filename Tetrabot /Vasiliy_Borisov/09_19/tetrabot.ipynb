{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNPteDfBUmBc/KeMKZEUXLD",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Untick/InspectrumClinic_RS_gr2/blob/main/Tetrabot%20/Vasiliy_Borisov/09_19/tetrabot.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Загружаем библиотеки, подключаем гугл диск"
      ],
      "metadata": {
        "id": "LA51b4k15ZBV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install SpeechRecognition\n",
        "!pip install fasttext\n",
        "import requests\n",
        "# from urllib.parse import urlencode\n",
        "# import json\n",
        "import gdown\n",
        "import os\n",
        "import zipfile\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from google.colab import drive\n",
        "import fasttext\n",
        "import speech_recognition as sr\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.models import Sequential, Model\n",
        "from tensorflow.keras.layers import Dense, Dropout, concatenate, Input, CategoryEncoding, Normalization, Activation, Conv1D\n",
        "from tensorflow.keras.optimizers import Adam, AdamW, RMSprop\n",
        "from tensorflow.keras import utils\n",
        "import tensorflow as tf\n",
        "\n",
        "\n",
        "r = sr.Recognizer()\n",
        "drive.mount('/content/gdrive')\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qoclv7AAqUy_",
        "outputId": "acee8fa7-9c82-45f5-caf6-4ca14197b8b7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting SpeechRecognition\n",
            "  Downloading SpeechRecognition-3.10.0-py2.py3-none-any.whl (32.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m32.8/32.8 MB\u001b[0m \u001b[31m18.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.10/dist-packages (from SpeechRecognition) (2.31.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->SpeechRecognition) (3.2.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->SpeechRecognition) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->SpeechRecognition) (2.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->SpeechRecognition) (2023.7.22)\n",
            "Installing collected packages: SpeechRecognition\n",
            "Successfully installed SpeechRecognition-3.10.0\n",
            "Collecting fasttext\n",
            "  Downloading fasttext-0.9.2.tar.gz (68 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m68.8/68.8 kB\u001b[0m \u001b[31m1.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting pybind11>=2.2 (from fasttext)\n",
            "  Using cached pybind11-2.11.1-py3-none-any.whl (227 kB)\n",
            "Requirement already satisfied: setuptools>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from fasttext) (67.7.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from fasttext) (1.23.5)\n",
            "Building wheels for collected packages: fasttext\n",
            "  Building wheel for fasttext (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for fasttext: filename=fasttext-0.9.2-cp310-cp310-linux_x86_64.whl size=4199771 sha256=dfabf469a8a83f4a9c89f22043ffcef26c019334e793bbdd74a080522cc7f2e9\n",
            "  Stored in directory: /root/.cache/pip/wheels/a5/13/75/f811c84a8ab36eedbaef977a6a58a98990e8e0f1967f98f394\n",
            "Successfully built fasttext\n",
            "Installing collected packages: pybind11, fasttext\n",
            "Successfully installed fasttext-0.9.2 pybind11-2.11.1\n",
            "Mounted at /content/gdrive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ft = fasttext.load_model('/content/gdrive/MyDrive/AI_data/cc.ru.300.bin')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "34Wf7L-_R9tI",
        "outputId": "51557aaa-2855-4c96-e0cd-b6ff66a1e674"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Warning : `load_model` does not return WordVectorModel or SupervisedModel any more, but a `FastText` object which is very similar.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Загружаем файл с разметкой"
      ],
      "metadata": {
        "id": "mKh_mxifeHUH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "x_train = []\n",
        "\n",
        "y_train_group = np.array([])\n",
        "y_train_action = np.array([])\n",
        "\n",
        "df_razmetka = pd.read_excel('/content/gdrive/MyDrive/AI_data/razmetka.xlsx')\n",
        "for idx, row in df_razmetka.iterrows():\n",
        "  x_train.append(ft.get_word_vector(row.text))\n",
        "y_train_group = df_razmetka['group'].to_numpy()\n",
        "y_train_action = df_razmetka['action'].to_numpy()"
      ],
      "metadata": {
        "id": "IUxtWZYXeG1q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print((x_train[1]))"
      ],
      "metadata": {
        "id": "eROndItGOJGp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Описываем и запускаем модель"
      ],
      "metadata": {
        "id": "Gl1f9QILeUaW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "trainY_group = tf.keras.utils.to_categorical(y_train_group)\n",
        "\n",
        "x_train = tf.stack(x_train)\n",
        "\n",
        "model_group = Sequential()\n",
        "model_group.add(Dense(len(x_train[0]), activation='relu'))\n",
        "model_group.add(Dense(800, activation='relu'))\n",
        "model_group.add(Dense(400, activation='relu'))\n",
        "model_group.add(Dense(trainY_group[0].shape[0], activation='softmax'))\n",
        "model_group.compile(optimizer=Adam(learning_rate=1e-3), loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "model_group.fit(x_train, trainY_group, batch_size=128, epochs=150, verbose=1)\n",
        "\n",
        "trainY_action = tf.keras.utils.to_categorical(y_train_action)\n",
        "\n",
        "model_action = Sequential()\n",
        "model_action.add(Dense(len(x_train[0]), activation='relu'))\n",
        "model_action.add(Dense(800, activation='relu'))\n",
        "model_action.add(Dense(400, activation='relu'))\n",
        "model_action.add(Dense(trainY_action[0].shape[0], activation='softmax'))\n",
        "model_action.compile(optimizer=Adam(learning_rate=1e-3), loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "model_action.fit(x_train, trainY_action, batch_size=128, epochs=150, verbose=1)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "MCacvf8_yyVU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "102365c6-c720-490f-bcf2-21426087dfba"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/150\n",
            "1/1 [==============================] - 3s 3s/step - loss: 2.2985 - accuracy: 0.1071\n",
            "Epoch 2/150\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 2.2297 - accuracy: 0.5833\n",
            "Epoch 3/150\n",
            "1/1 [==============================] - 0s 52ms/step - loss: 2.1528 - accuracy: 0.5833\n",
            "Epoch 4/150\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 2.0524 - accuracy: 0.5833\n",
            "Epoch 5/150\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 1.9217 - accuracy: 0.5833\n",
            "Epoch 6/150\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 1.7639 - accuracy: 0.5833\n",
            "Epoch 7/150\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 1.6031 - accuracy: 0.5833\n",
            "Epoch 8/150\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 1.4807 - accuracy: 0.5833\n",
            "Epoch 9/150\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 1.4208 - accuracy: 0.5833\n",
            "Epoch 10/150\n",
            "1/1 [==============================] - 0s 45ms/step - loss: 1.3821 - accuracy: 0.5833\n",
            "Epoch 11/150\n",
            "1/1 [==============================] - 0s 50ms/step - loss: 1.3132 - accuracy: 0.5833\n",
            "Epoch 12/150\n",
            "1/1 [==============================] - 0s 57ms/step - loss: 1.2263 - accuracy: 0.6310\n",
            "Epoch 13/150\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 1.1533 - accuracy: 0.6548\n",
            "Epoch 14/150\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 1.1061 - accuracy: 0.6786\n",
            "Epoch 15/150\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 1.0705 - accuracy: 0.7024\n",
            "Epoch 16/150\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 1.0267 - accuracy: 0.7024\n",
            "Epoch 17/150\n",
            "1/1 [==============================] - 0s 51ms/step - loss: 0.9703 - accuracy: 0.7143\n",
            "Epoch 18/150\n",
            "1/1 [==============================] - 0s 58ms/step - loss: 0.9137 - accuracy: 0.7143\n",
            "Epoch 19/150\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 0.8682 - accuracy: 0.7143\n",
            "Epoch 20/150\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 0.8302 - accuracy: 0.7143\n",
            "Epoch 21/150\n",
            "1/1 [==============================] - 0s 56ms/step - loss: 0.7882 - accuracy: 0.7143\n",
            "Epoch 22/150\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.7386 - accuracy: 0.7143\n",
            "Epoch 23/150\n",
            "1/1 [==============================] - 0s 50ms/step - loss: 0.6892 - accuracy: 0.7619\n",
            "Epoch 24/150\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 0.6467 - accuracy: 0.7738\n",
            "Epoch 25/150\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 0.6057 - accuracy: 0.7976\n",
            "Epoch 26/150\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 0.5581 - accuracy: 0.8095\n",
            "Epoch 27/150\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 0.5080 - accuracy: 0.8095\n",
            "Epoch 28/150\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 0.4645 - accuracy: 0.8214\n",
            "Epoch 29/150\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.4260 - accuracy: 0.8214\n",
            "Epoch 30/150\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 0.3855 - accuracy: 0.8690\n",
            "Epoch 31/150\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 0.3433 - accuracy: 0.8929\n",
            "Epoch 32/150\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 0.3053 - accuracy: 0.9167\n",
            "Epoch 33/150\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 0.2715 - accuracy: 0.9524\n",
            "Epoch 34/150\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 0.2378 - accuracy: 0.9524\n",
            "Epoch 35/150\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 0.2050 - accuracy: 0.9524\n",
            "Epoch 36/150\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 0.1765 - accuracy: 0.9524\n",
            "Epoch 37/150\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.1529 - accuracy: 0.9524\n",
            "Epoch 38/150\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.1321 - accuracy: 0.9643\n",
            "Epoch 39/150\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.1132 - accuracy: 0.9762\n",
            "Epoch 40/150\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.0968 - accuracy: 0.9762\n",
            "Epoch 41/150\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.0832 - accuracy: 1.0000\n",
            "Epoch 42/150\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.0718 - accuracy: 1.0000\n",
            "Epoch 43/150\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.0617 - accuracy: 1.0000\n",
            "Epoch 44/150\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.0522 - accuracy: 1.0000\n",
            "Epoch 45/150\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.0438 - accuracy: 1.0000\n",
            "Epoch 46/150\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.0369 - accuracy: 1.0000\n",
            "Epoch 47/150\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.0313 - accuracy: 1.0000\n",
            "Epoch 48/150\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.0265 - accuracy: 1.0000\n",
            "Epoch 49/150\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.0222 - accuracy: 1.0000\n",
            "Epoch 50/150\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.0185 - accuracy: 1.0000\n",
            "Epoch 51/150\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.0154 - accuracy: 1.0000\n",
            "Epoch 52/150\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.0129 - accuracy: 1.0000\n",
            "Epoch 53/150\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.0110 - accuracy: 1.0000\n",
            "Epoch 54/150\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.0095 - accuracy: 1.0000\n",
            "Epoch 55/150\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.0081 - accuracy: 1.0000\n",
            "Epoch 56/150\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.0070 - accuracy: 1.0000\n",
            "Epoch 57/150\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.0060 - accuracy: 1.0000\n",
            "Epoch 58/150\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.0052 - accuracy: 1.0000\n",
            "Epoch 59/150\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.0045 - accuracy: 1.0000\n",
            "Epoch 60/150\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.0039 - accuracy: 1.0000\n",
            "Epoch 61/150\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.0034 - accuracy: 1.0000\n",
            "Epoch 62/150\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.0030 - accuracy: 1.0000\n",
            "Epoch 63/150\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 0.0027 - accuracy: 1.0000\n",
            "Epoch 64/150\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.0024 - accuracy: 1.0000\n",
            "Epoch 65/150\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.0022 - accuracy: 1.0000\n",
            "Epoch 66/150\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 0.0020 - accuracy: 1.0000\n",
            "Epoch 67/150\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.0018 - accuracy: 1.0000\n",
            "Epoch 68/150\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.0016 - accuracy: 1.0000\n",
            "Epoch 69/150\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.0015 - accuracy: 1.0000\n",
            "Epoch 70/150\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.0014 - accuracy: 1.0000\n",
            "Epoch 71/150\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.0013 - accuracy: 1.0000\n",
            "Epoch 72/150\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.0012 - accuracy: 1.0000\n",
            "Epoch 73/150\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.0011 - accuracy: 1.0000\n",
            "Epoch 74/150\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.0010 - accuracy: 1.0000\n",
            "Epoch 75/150\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 9.5580e-04 - accuracy: 1.0000\n",
            "Epoch 76/150\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 8.9970e-04 - accuracy: 1.0000\n",
            "Epoch 77/150\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 8.4998e-04 - accuracy: 1.0000\n",
            "Epoch 78/150\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 8.0573e-04 - accuracy: 1.0000\n",
            "Epoch 79/150\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 7.6621e-04 - accuracy: 1.0000\n",
            "Epoch 80/150\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 7.3068e-04 - accuracy: 1.0000\n",
            "Epoch 81/150\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 6.9861e-04 - accuracy: 1.0000\n",
            "Epoch 82/150\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 6.6949e-04 - accuracy: 1.0000\n",
            "Epoch 83/150\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 6.4296e-04 - accuracy: 1.0000\n",
            "Epoch 84/150\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 6.1870e-04 - accuracy: 1.0000\n",
            "Epoch 85/150\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 5.9643e-04 - accuracy: 1.0000\n",
            "Epoch 86/150\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 5.7591e-04 - accuracy: 1.0000\n",
            "Epoch 87/150\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 5.5692e-04 - accuracy: 1.0000\n",
            "Epoch 88/150\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 5.3933e-04 - accuracy: 1.0000\n",
            "Epoch 89/150\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 5.2292e-04 - accuracy: 1.0000\n",
            "Epoch 90/150\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 5.0763e-04 - accuracy: 1.0000\n",
            "Epoch 91/150\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 4.9334e-04 - accuracy: 1.0000\n",
            "Epoch 92/150\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 4.7996e-04 - accuracy: 1.0000\n",
            "Epoch 93/150\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 4.6744e-04 - accuracy: 1.0000\n",
            "Epoch 94/150\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 4.5569e-04 - accuracy: 1.0000\n",
            "Epoch 95/150\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 4.4461e-04 - accuracy: 1.0000\n",
            "Epoch 96/150\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 4.3418e-04 - accuracy: 1.0000\n",
            "Epoch 97/150\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 4.2435e-04 - accuracy: 1.0000\n",
            "Epoch 98/150\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 4.1505e-04 - accuracy: 1.0000\n",
            "Epoch 99/150\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 4.0626e-04 - accuracy: 1.0000\n",
            "Epoch 100/150\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 3.9792e-04 - accuracy: 1.0000\n",
            "Epoch 101/150\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 3.9000e-04 - accuracy: 1.0000\n",
            "Epoch 102/150\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 3.8247e-04 - accuracy: 1.0000\n",
            "Epoch 103/150\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 3.7529e-04 - accuracy: 1.0000\n",
            "Epoch 104/150\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 3.6842e-04 - accuracy: 1.0000\n",
            "Epoch 105/150\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 3.6186e-04 - accuracy: 1.0000\n",
            "Epoch 106/150\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 3.5558e-04 - accuracy: 1.0000\n",
            "Epoch 107/150\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 3.4954e-04 - accuracy: 1.0000\n",
            "Epoch 108/150\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 3.4375e-04 - accuracy: 1.0000\n",
            "Epoch 109/150\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 3.3816e-04 - accuracy: 1.0000\n",
            "Epoch 110/150\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 3.3278e-04 - accuracy: 1.0000\n",
            "Epoch 111/150\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 3.2761e-04 - accuracy: 1.0000\n",
            "Epoch 112/150\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 3.2258e-04 - accuracy: 1.0000\n",
            "Epoch 113/150\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 3.1773e-04 - accuracy: 1.0000\n",
            "Epoch 114/150\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 3.1303e-04 - accuracy: 1.0000\n",
            "Epoch 115/150\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 3.0847e-04 - accuracy: 1.0000\n",
            "Epoch 116/150\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 3.0406e-04 - accuracy: 1.0000\n",
            "Epoch 117/150\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 2.9976e-04 - accuracy: 1.0000\n",
            "Epoch 118/150\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 2.9560e-04 - accuracy: 1.0000\n",
            "Epoch 119/150\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 2.9156e-04 - accuracy: 1.0000\n",
            "Epoch 120/150\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 2.8762e-04 - accuracy: 1.0000\n",
            "Epoch 121/150\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 2.8378e-04 - accuracy: 1.0000\n",
            "Epoch 122/150\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 2.8004e-04 - accuracy: 1.0000\n",
            "Epoch 123/150\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 2.7639e-04 - accuracy: 1.0000\n",
            "Epoch 124/150\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 2.7282e-04 - accuracy: 1.0000\n",
            "Epoch 125/150\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 2.6934e-04 - accuracy: 1.0000\n",
            "Epoch 126/150\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 2.6592e-04 - accuracy: 1.0000\n",
            "Epoch 127/150\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 2.6258e-04 - accuracy: 1.0000\n",
            "Epoch 128/150\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 2.5932e-04 - accuracy: 1.0000\n",
            "Epoch 129/150\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 2.5613e-04 - accuracy: 1.0000\n",
            "Epoch 130/150\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 2.5300e-04 - accuracy: 1.0000\n",
            "Epoch 131/150\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 2.4994e-04 - accuracy: 1.0000\n",
            "Epoch 132/150\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 2.4694e-04 - accuracy: 1.0000\n",
            "Epoch 133/150\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 2.4399e-04 - accuracy: 1.0000\n",
            "Epoch 134/150\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 2.4110e-04 - accuracy: 1.0000\n",
            "Epoch 135/150\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 2.3828e-04 - accuracy: 1.0000\n",
            "Epoch 136/150\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 2.3551e-04 - accuracy: 1.0000\n",
            "Epoch 137/150\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 2.3278e-04 - accuracy: 1.0000\n",
            "Epoch 138/150\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 2.3011e-04 - accuracy: 1.0000\n",
            "Epoch 139/150\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 2.2749e-04 - accuracy: 1.0000\n",
            "Epoch 140/150\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 2.2490e-04 - accuracy: 1.0000\n",
            "Epoch 141/150\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 2.2238e-04 - accuracy: 1.0000\n",
            "Epoch 142/150\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 2.1988e-04 - accuracy: 1.0000\n",
            "Epoch 143/150\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 2.1744e-04 - accuracy: 1.0000\n",
            "Epoch 144/150\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 2.1503e-04 - accuracy: 1.0000\n",
            "Epoch 145/150\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 2.1268e-04 - accuracy: 1.0000\n",
            "Epoch 146/150\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 2.1035e-04 - accuracy: 1.0000\n",
            "Epoch 147/150\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 2.0807e-04 - accuracy: 1.0000\n",
            "Epoch 148/150\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 2.0582e-04 - accuracy: 1.0000\n",
            "Epoch 149/150\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 2.0361e-04 - accuracy: 1.0000\n",
            "Epoch 150/150\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 2.0144e-04 - accuracy: 1.0000\n",
            "Epoch 1/150\n",
            "1/1 [==============================] - 1s 887ms/step - loss: 1.9441 - accuracy: 0.1786\n",
            "Epoch 2/150\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 1.9028 - accuracy: 0.3690\n",
            "Epoch 3/150\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 1.8615 - accuracy: 0.3690\n",
            "Epoch 4/150\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 1.8118 - accuracy: 0.3571\n",
            "Epoch 5/150\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 1.7506 - accuracy: 0.3571\n",
            "Epoch 6/150\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 1.6785 - accuracy: 0.3571\n",
            "Epoch 7/150\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 1.5996 - accuracy: 0.3690\n",
            "Epoch 8/150\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 1.5201 - accuracy: 0.3690\n",
            "Epoch 9/150\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 1.4443 - accuracy: 0.3929\n",
            "Epoch 10/150\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 1.3743 - accuracy: 0.5000\n",
            "Epoch 11/150\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 1.3086 - accuracy: 0.6429\n",
            "Epoch 12/150\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 1.2419 - accuracy: 0.6667\n",
            "Epoch 13/150\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 1.1719 - accuracy: 0.6667\n",
            "Epoch 14/150\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 1.1027 - accuracy: 0.6905\n",
            "Epoch 15/150\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 1.0332 - accuracy: 0.6786\n",
            "Epoch 16/150\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.9608 - accuracy: 0.7024\n",
            "Epoch 17/150\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.8884 - accuracy: 0.7262\n",
            "Epoch 18/150\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.8158 - accuracy: 0.7381\n",
            "Epoch 19/150\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.7432 - accuracy: 0.7381\n",
            "Epoch 20/150\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.6718 - accuracy: 0.7262\n",
            "Epoch 21/150\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.6041 - accuracy: 0.7857\n",
            "Epoch 22/150\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.5412 - accuracy: 0.8333\n",
            "Epoch 23/150\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.4810 - accuracy: 0.8452\n",
            "Epoch 24/150\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.4232 - accuracy: 0.8571\n",
            "Epoch 25/150\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.3703 - accuracy: 0.9048\n",
            "Epoch 26/150\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.3214 - accuracy: 0.9524\n",
            "Epoch 27/150\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.2781 - accuracy: 0.9643\n",
            "Epoch 28/150\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.2398 - accuracy: 0.9643\n",
            "Epoch 29/150\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.2065 - accuracy: 0.9762\n",
            "Epoch 30/150\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.1772 - accuracy: 0.9762\n",
            "Epoch 31/150\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.1527 - accuracy: 0.9762\n",
            "Epoch 32/150\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.1322 - accuracy: 0.9881\n",
            "Epoch 33/150\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.1136 - accuracy: 1.0000\n",
            "Epoch 34/150\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.0973 - accuracy: 1.0000\n",
            "Epoch 35/150\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.0836 - accuracy: 1.0000\n",
            "Epoch 36/150\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.0711 - accuracy: 1.0000\n",
            "Epoch 37/150\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.0604 - accuracy: 1.0000\n",
            "Epoch 38/150\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.0511 - accuracy: 1.0000\n",
            "Epoch 39/150\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.0426 - accuracy: 1.0000\n",
            "Epoch 40/150\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.0355 - accuracy: 1.0000\n",
            "Epoch 41/150\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.0296 - accuracy: 1.0000\n",
            "Epoch 42/150\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.0245 - accuracy: 1.0000\n",
            "Epoch 43/150\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.0203 - accuracy: 1.0000\n",
            "Epoch 44/150\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.0169 - accuracy: 1.0000\n",
            "Epoch 45/150\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.0139 - accuracy: 1.0000\n",
            "Epoch 46/150\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.0115 - accuracy: 1.0000\n",
            "Epoch 47/150\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.0096 - accuracy: 1.0000\n",
            "Epoch 48/150\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.0080 - accuracy: 1.0000\n",
            "Epoch 49/150\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.0067 - accuracy: 1.0000\n",
            "Epoch 50/150\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.0056 - accuracy: 1.0000\n",
            "Epoch 51/150\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.0047 - accuracy: 1.0000\n",
            "Epoch 52/150\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.0040 - accuracy: 1.0000\n",
            "Epoch 53/150\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.0034 - accuracy: 1.0000\n",
            "Epoch 54/150\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.0029 - accuracy: 1.0000\n",
            "Epoch 55/150\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.0025 - accuracy: 1.0000\n",
            "Epoch 56/150\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.0022 - accuracy: 1.0000\n",
            "Epoch 57/150\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.0019 - accuracy: 1.0000\n",
            "Epoch 58/150\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.0017 - accuracy: 1.0000\n",
            "Epoch 59/150\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.0015 - accuracy: 1.0000\n",
            "Epoch 60/150\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.0013 - accuracy: 1.0000\n",
            "Epoch 61/150\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.0012 - accuracy: 1.0000\n",
            "Epoch 62/150\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.0011 - accuracy: 1.0000\n",
            "Epoch 63/150\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 9.8715e-04 - accuracy: 1.0000\n",
            "Epoch 64/150\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 9.0606e-04 - accuracy: 1.0000\n",
            "Epoch 65/150\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 8.3664e-04 - accuracy: 1.0000\n",
            "Epoch 66/150\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 7.7674e-04 - accuracy: 1.0000\n",
            "Epoch 67/150\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 7.2473e-04 - accuracy: 1.0000\n",
            "Epoch 68/150\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 6.7937e-04 - accuracy: 1.0000\n",
            "Epoch 69/150\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 6.3964e-04 - accuracy: 1.0000\n",
            "Epoch 70/150\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 6.0465e-04 - accuracy: 1.0000\n",
            "Epoch 71/150\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 5.7375e-04 - accuracy: 1.0000\n",
            "Epoch 72/150\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 5.4635e-04 - accuracy: 1.0000\n",
            "Epoch 73/150\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 5.2193e-04 - accuracy: 1.0000\n",
            "Epoch 74/150\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 5.0008e-04 - accuracy: 1.0000\n",
            "Epoch 75/150\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 4.8041e-04 - accuracy: 1.0000\n",
            "Epoch 76/150\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 4.6263e-04 - accuracy: 1.0000\n",
            "Epoch 77/150\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 4.4650e-04 - accuracy: 1.0000\n",
            "Epoch 78/150\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 4.3177e-04 - accuracy: 1.0000\n",
            "Epoch 79/150\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 4.1828e-04 - accuracy: 1.0000\n",
            "Epoch 80/150\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 4.0597e-04 - accuracy: 1.0000\n",
            "Epoch 81/150\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 3.9468e-04 - accuracy: 1.0000\n",
            "Epoch 82/150\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 3.8432e-04 - accuracy: 1.0000\n",
            "Epoch 83/150\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 3.7478e-04 - accuracy: 1.0000\n",
            "Epoch 84/150\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 3.6598e-04 - accuracy: 1.0000\n",
            "Epoch 85/150\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 3.5783e-04 - accuracy: 1.0000\n",
            "Epoch 86/150\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 3.5027e-04 - accuracy: 1.0000\n",
            "Epoch 87/150\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 3.4320e-04 - accuracy: 1.0000\n",
            "Epoch 88/150\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 3.3661e-04 - accuracy: 1.0000\n",
            "Epoch 89/150\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 3.3040e-04 - accuracy: 1.0000\n",
            "Epoch 90/150\n",
            "1/1 [==============================] - 0s 296ms/step - loss: 3.2456e-04 - accuracy: 1.0000\n",
            "Epoch 91/150\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 3.1907e-04 - accuracy: 1.0000\n",
            "Epoch 92/150\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 3.1385e-04 - accuracy: 1.0000\n",
            "Epoch 93/150\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 3.0892e-04 - accuracy: 1.0000\n",
            "Epoch 94/150\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 3.0422e-04 - accuracy: 1.0000\n",
            "Epoch 95/150\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 2.9977e-04 - accuracy: 1.0000\n",
            "Epoch 96/150\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 2.9553e-04 - accuracy: 1.0000\n",
            "Epoch 97/150\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 2.9149e-04 - accuracy: 1.0000\n",
            "Epoch 98/150\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 2.8763e-04 - accuracy: 1.0000\n",
            "Epoch 99/150\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 2.8393e-04 - accuracy: 1.0000\n",
            "Epoch 100/150\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 2.8037e-04 - accuracy: 1.0000\n",
            "Epoch 101/150\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 2.7694e-04 - accuracy: 1.0000\n",
            "Epoch 102/150\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 2.7364e-04 - accuracy: 1.0000\n",
            "Epoch 103/150\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 2.7044e-04 - accuracy: 1.0000\n",
            "Epoch 104/150\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 2.6736e-04 - accuracy: 1.0000\n",
            "Epoch 105/150\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 2.6437e-04 - accuracy: 1.0000\n",
            "Epoch 106/150\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 2.6148e-04 - accuracy: 1.0000\n",
            "Epoch 107/150\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 2.5868e-04 - accuracy: 1.0000\n",
            "Epoch 108/150\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 2.5596e-04 - accuracy: 1.0000\n",
            "Epoch 109/150\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 2.5330e-04 - accuracy: 1.0000\n",
            "Epoch 110/150\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 2.5071e-04 - accuracy: 1.0000\n",
            "Epoch 111/150\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 2.4817e-04 - accuracy: 1.0000\n",
            "Epoch 112/150\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 2.4571e-04 - accuracy: 1.0000\n",
            "Epoch 113/150\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 2.4331e-04 - accuracy: 1.0000\n",
            "Epoch 114/150\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 2.4097e-04 - accuracy: 1.0000\n",
            "Epoch 115/150\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 2.3867e-04 - accuracy: 1.0000\n",
            "Epoch 116/150\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 2.3643e-04 - accuracy: 1.0000\n",
            "Epoch 117/150\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 2.3423e-04 - accuracy: 1.0000\n",
            "Epoch 118/150\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 2.3207e-04 - accuracy: 1.0000\n",
            "Epoch 119/150\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 2.2997e-04 - accuracy: 1.0000\n",
            "Epoch 120/150\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 2.2788e-04 - accuracy: 1.0000\n",
            "Epoch 121/150\n",
            "1/1 [==============================] - 0s 45ms/step - loss: 2.2584e-04 - accuracy: 1.0000\n",
            "Epoch 122/150\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 2.2385e-04 - accuracy: 1.0000\n",
            "Epoch 123/150\n",
            "1/1 [==============================] - 0s 54ms/step - loss: 2.2188e-04 - accuracy: 1.0000\n",
            "Epoch 124/150\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 2.1993e-04 - accuracy: 1.0000\n",
            "Epoch 125/150\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 2.1803e-04 - accuracy: 1.0000\n",
            "Epoch 126/150\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 2.1616e-04 - accuracy: 1.0000\n",
            "Epoch 127/150\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 2.1432e-04 - accuracy: 1.0000\n",
            "Epoch 128/150\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 2.1250e-04 - accuracy: 1.0000\n",
            "Epoch 129/150\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 2.1072e-04 - accuracy: 1.0000\n",
            "Epoch 130/150\n",
            "1/1 [==============================] - 0s 54ms/step - loss: 2.0896e-04 - accuracy: 1.0000\n",
            "Epoch 131/150\n",
            "1/1 [==============================] - 0s 52ms/step - loss: 2.0723e-04 - accuracy: 1.0000\n",
            "Epoch 132/150\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 2.0552e-04 - accuracy: 1.0000\n",
            "Epoch 133/150\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 2.0385e-04 - accuracy: 1.0000\n",
            "Epoch 134/150\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 2.0219e-04 - accuracy: 1.0000\n",
            "Epoch 135/150\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 2.0056e-04 - accuracy: 1.0000\n",
            "Epoch 136/150\n",
            "1/1 [==============================] - 0s 60ms/step - loss: 1.9894e-04 - accuracy: 1.0000\n",
            "Epoch 137/150\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 1.9736e-04 - accuracy: 1.0000\n",
            "Epoch 138/150\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 1.9578e-04 - accuracy: 1.0000\n",
            "Epoch 139/150\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 1.9425e-04 - accuracy: 1.0000\n",
            "Epoch 140/150\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 1.9271e-04 - accuracy: 1.0000\n",
            "Epoch 141/150\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 1.9120e-04 - accuracy: 1.0000\n",
            "Epoch 142/150\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 1.8972e-04 - accuracy: 1.0000\n",
            "Epoch 143/150\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 1.8825e-04 - accuracy: 1.0000\n",
            "Epoch 144/150\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 1.8679e-04 - accuracy: 1.0000\n",
            "Epoch 145/150\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 1.8535e-04 - accuracy: 1.0000\n",
            "Epoch 146/150\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 1.8394e-04 - accuracy: 1.0000\n",
            "Epoch 147/150\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 1.8254e-04 - accuracy: 1.0000\n",
            "Epoch 148/150\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 1.8116e-04 - accuracy: 1.0000\n",
            "Epoch 149/150\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 1.7978e-04 - accuracy: 1.0000\n",
            "Epoch 150/150\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 1.7843e-04 - accuracy: 1.0000\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x7d479e37ad40>"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Описываем функцию распознавани аудио при помощи recognize_google"
      ],
      "metadata": {
        "id": "JXSCY4eBewDm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def recognize_file_def(AudioFile):\n",
        "  AudioFile = sr.AudioFile(AudioFile)\n",
        "  with AudioFile as source:\n",
        "      audio = r.record(source)\n",
        "      return r.recognize_google(audio, language=\"ru-RU\")"
      ],
      "metadata": {
        "id": "0MGxmuFZzpt_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Перебираем файлы, распознаем текст"
      ],
      "metadata": {
        "id": "uLeiCuaL59fJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.DataFrame(columns=[\"file\", \"text\", \"vector\"])#, \"text\", \"vector\")\n",
        "\n",
        "x_predict = []\n",
        "\n",
        "def search_all_files(directory):\n",
        "  for filename in os.listdir(directory):\n",
        "    if \"chunk\" in filename:\n",
        "        f = os.path.join(directory, filename)\n",
        "        # checking if it is a file\n",
        "        if os.path.isfile(f):\n",
        "          if os.path.getsize(f)<90000000:\n",
        "            recognize_file = recognize_file_def(f)\n",
        "            word_vector = ft.get_word_vector(recognize_file)\n",
        "            x_predict.append(word_vector)\n",
        "            # word_vector = ft.get_word_vector(recognize_file)\n",
        "            df.loc[ len(df.index )] = [f, recognize_file, word_vector]\n",
        "        else:\n",
        "          search_all_files(f)\n",
        "\n",
        "search_all_files('/content/gdrive/MyDrive/AI_data/golos_blizko')\n",
        "df.to_excel(\"/content/gdrive/MyDrive/AI_data/df.xlsx\")\n"
      ],
      "metadata": {
        "id": "FWOZxaCAJW8V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# (x_train[1][2])\n",
        "x_predict = tf.stack(x_predict)"
      ],
      "metadata": {
        "id": "kyDB30OiS4A5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(x_predict)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZCHbRWwPUK-d",
        "outputId": "6976d368-fd8c-4f44-ece6-b1505427ea91"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor(\n",
            "[[ 0.01934599 -0.01369245 -0.00029067 ...  0.00233922 -0.00719262\n",
            "  -0.01895417]\n",
            " [ 0.01971263 -0.01710786  0.01421099 ...  0.00729356  0.00133919\n",
            "  -0.0179143 ]\n",
            " [ 0.01272598 -0.02894953  0.00155694 ... -0.00242595 -0.02604934\n",
            "  -0.02335784]\n",
            " ...\n",
            " [ 0.02442752 -0.01972329  0.01674293 ... -0.00585412 -0.02110018\n",
            "  -0.03100809]\n",
            " [ 0.00353123 -0.02000297  0.00148613 ...  0.01097282 -0.04391326\n",
            "  -0.02362892]\n",
            " [ 0.01311401 -0.02285752 -0.00102524 ... -0.00992145 -0.02438494\n",
            "  -0.02608792]], shape=(97, 300), dtype=float32)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Пропускаем распознанный текст  через нашу модель"
      ],
      "metadata": {
        "id": "Ursc0wqDDox1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print((x_predict[0][0]))\n",
        "print(x_train[0][0])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rhjoVLS-mIjT",
        "outputId": "6eb967dc-b55f-44f2-8eac-4498c478241e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor(0.01934599, shape=(), dtype=float32)\n",
            "tf.Tensor(0.030854637, shape=(), dtype=float32)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(x_predict[0]))\n",
        "prediction\n",
        "model.summary()\n",
        "print(prediction[0])\n",
        "(np.argmax(prediction[0]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wdHLCcKxYTcx",
        "outputId": "041d7fc6-45bb-4f61-8d2a-e853e14c55fd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "300\n",
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense (Dense)               (None, 300)               90300     \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 800)               240800    \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 400)               320400    \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 10)                4010      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 655510 (2.50 MB)\n",
            "Trainable params: 655510 (2.50 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n",
            "[3.7744860e-07 9.5897216e-01 9.6652839e-05 1.7588292e-03 3.8480707e-06\n",
            " 3.5315854e-06 6.7758887e-10 5.8939709e-10 9.5375075e-10 3.9164513e-02]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1"
            ]
          },
          "metadata": {},
          "execution_count": 84
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(x_predict[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YFzTSwO3gFC3",
        "outputId": "4e0ae612-366c-45bc-810c-469ba04c6074"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "300"
            ]
          },
          "metadata": {},
          "execution_count": 88
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "prediction_group = model_group.predict(x_predict)\n",
        "prediction_action = model_action.predict(x_predict)\n",
        "for index, row in df.iterrows():\n",
        "  print(len(x_predict[index]))\n",
        "\n",
        "  print(np.argmax(prediction_group[index]))\n",
        "  print(np.argmax(prediction_action[index]))\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "Fys4KbSFG2Sh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2790489f-003d-4c1f-f776-6f959da2dc8f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "4/4 [==============================] - 0s 6ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "300\n",
            "1\n",
            "1\n",
            "300\n",
            "2\n",
            "4\n",
            "300\n",
            "1\n",
            "5\n",
            "300\n",
            "2\n",
            "3\n",
            "300\n",
            "3\n",
            "1\n",
            "300\n",
            "3\n",
            "1\n",
            "300\n",
            "3\n",
            "1\n",
            "300\n",
            "9\n",
            "1\n",
            "300\n",
            "1\n",
            "4\n",
            "300\n",
            "1\n",
            "6\n",
            "300\n",
            "1\n",
            "2\n",
            "300\n",
            "1\n",
            "1\n",
            "300\n",
            "1\n",
            "1\n",
            "300\n",
            "1\n",
            "1\n",
            "300\n",
            "1\n",
            "3\n",
            "300\n",
            "1\n",
            "1\n",
            "300\n",
            "1\n",
            "4\n",
            "300\n",
            "1\n",
            "4\n",
            "300\n",
            "1\n",
            "3\n",
            "300\n",
            "1\n",
            "3\n",
            "300\n",
            "1\n",
            "3\n",
            "300\n",
            "1\n",
            "4\n",
            "300\n",
            "1\n",
            "6\n",
            "300\n",
            "1\n",
            "6\n",
            "300\n",
            "1\n",
            "6\n",
            "300\n",
            "5\n",
            "1\n",
            "300\n",
            "5\n",
            "1\n",
            "300\n",
            "9\n",
            "1\n",
            "300\n",
            "1\n",
            "4\n",
            "300\n",
            "1\n",
            "4\n",
            "300\n",
            "1\n",
            "3\n",
            "300\n",
            "1\n",
            "3\n",
            "300\n",
            "9\n",
            "1\n",
            "300\n",
            "9\n",
            "1\n",
            "300\n",
            "9\n",
            "1\n",
            "300\n",
            "1\n",
            "6\n",
            "300\n",
            "4\n",
            "6\n",
            "300\n",
            "4\n",
            "6\n",
            "300\n",
            "1\n",
            "5\n",
            "300\n",
            "1\n",
            "5\n",
            "300\n",
            "1\n",
            "5\n",
            "300\n",
            "1\n",
            "2\n",
            "300\n",
            "1\n",
            "2\n",
            "300\n",
            "1\n",
            "2\n",
            "300\n",
            "1\n",
            "1\n",
            "300\n",
            "1\n",
            "1\n",
            "300\n",
            "1\n",
            "1\n",
            "300\n",
            "5\n",
            "6\n",
            "300\n",
            "5\n",
            "6\n",
            "300\n",
            "0\n",
            "0\n",
            "300\n",
            "0\n",
            "0\n",
            "300\n",
            "0\n",
            "0\n",
            "300\n",
            "2\n",
            "5\n",
            "300\n",
            "2\n",
            "5\n",
            "300\n",
            "2\n",
            "1\n",
            "300\n",
            "1\n",
            "6\n",
            "300\n",
            "1\n",
            "6\n",
            "300\n",
            "1\n",
            "6\n",
            "300\n",
            "1\n",
            "3\n",
            "300\n",
            "1\n",
            "3\n",
            "300\n",
            "1\n",
            "4\n",
            "300\n",
            "1\n",
            "4\n",
            "300\n",
            "1\n",
            "5\n",
            "300\n",
            "0\n",
            "0\n",
            "300\n",
            "0\n",
            "0\n",
            "300\n",
            "0\n",
            "0\n",
            "300\n",
            "1\n",
            "1\n",
            "300\n",
            "1\n",
            "1\n",
            "300\n",
            "1\n",
            "2\n",
            "300\n",
            "1\n",
            "2\n",
            "300\n",
            "1\n",
            "2\n",
            "300\n",
            "3\n",
            "6\n",
            "300\n",
            "3\n",
            "6\n",
            "300\n",
            "3\n",
            "6\n",
            "300\n",
            "4\n",
            "1\n",
            "300\n",
            "4\n",
            "1\n",
            "300\n",
            "4\n",
            "1\n",
            "300\n",
            "2\n",
            "2\n",
            "300\n",
            "2\n",
            "2\n",
            "300\n",
            "2\n",
            "6\n",
            "300\n",
            "2\n",
            "6\n",
            "300\n",
            "1\n",
            "6\n",
            "300\n",
            "1\n",
            "6\n",
            "300\n",
            "1\n",
            "1\n",
            "300\n",
            "1\n",
            "1\n",
            "300\n",
            "1\n",
            "1\n",
            "300\n",
            "1\n",
            "1\n",
            "300\n",
            "1\n",
            "1\n",
            "300\n",
            "1\n",
            "1\n",
            "300\n",
            "1\n",
            "1\n",
            "300\n",
            "1\n",
            "4\n",
            "300\n",
            "1\n",
            "6\n",
            "300\n",
            "1\n",
            "6\n",
            "300\n",
            "1\n",
            "6\n",
            "300\n",
            "1\n",
            "6\n",
            "300\n",
            "1\n",
            "6\n",
            "300\n",
            "1\n",
            "6\n"
          ]
        }
      ]
    }
  ]
}